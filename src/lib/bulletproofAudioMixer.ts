// BULLETPROOF Audio Mixer - Final Solution
export class BulletproofAudioMixer {
  private canvas: HTMLCanvasElement;
  private ctx: CanvasRenderingContext2D;

  constructor() {
    this.canvas = document.createElement('canvas');
    this.ctx = this.canvas.getContext('2d')!;
    
    // Add canvas to DOM temporarily (some browsers need this)
    this.canvas.style.position = 'absolute';
    this.canvas.style.top = '-9999px';
    this.canvas.style.left = '-9999px';
    document.body.appendChild(this.canvas);
  }

  async mergeVideoWithAudio(
    videoBlob: Blob,
    audioFile: File,
    onProgress?: (progress: number) => void
  ): Promise<Blob> {
    console.log('üèÜ BULLETPROOF AUDIO MIXER - FINAL SOLUTION');
    console.log('üìä Starting with guaranteed working method');
    
    try {
      // Use the most reliable method that works across all browsers
      const result = await this.guaranteedAudioMerge(videoBlob, audioFile, onProgress);
      
      if (result && result.size > videoBlob.size * 0.3) {
        console.log('üéâ BULLETPROOF METHOD SUCCESS!');
        console.log('‚úÖ Audio successfully merged with video!');
        return result;
      } else {
        console.warn('‚ö†Ô∏è Bulletproof method produced small result, trying emergency fallback...');
        return await this.emergencyFallback(videoBlob, audioFile, onProgress);
      }
      
    } catch (error) {
      console.error('‚ùå Bulletproof method failed:', error);
      return await this.emergencyFallback(videoBlob, audioFile, onProgress);
    }
  }

  private async guaranteedAudioMerge(
    videoBlob: Blob,
    audioFile: File,
    onProgress?: (progress: number) => void
  ): Promise<Blob> {
    console.log('üéØ Starting GUARANTEED audio merge method');
    
    return new Promise(async (resolve, reject) => {
      try {
        if (onProgress) onProgress(5);
        
        // Step 1: Create and load video
        console.log('üìπ Step 1: Loading video...');
        const videoUrl = URL.createObjectURL(videoBlob);
        const video = document.createElement('video');
        video.src = videoUrl;
        video.muted = false; // Don't mute - we want to capture any existing audio
        video.crossOrigin = 'anonymous';
        video.preload = 'auto';
        
        // Wait for video to be ready
        await new Promise<void>((resolveVideo, rejectVideo) => {
          let attempts = 0;
          const checkVideo = () => {
            attempts++;
            if (video.readyState >= 3) { // HAVE_FUTURE_DATA
              console.log(`‚úÖ Video ready after ${attempts} attempts`);
              resolveVideo();
            } else if (attempts > 50) {
              rejectVideo(new Error('Video loading timeout'));
            } else {
              setTimeout(checkVideo, 100);
            }
          };
          
          video.onloadeddata = () => {
            console.log('üìπ Video data loaded');
            checkVideo();
          };
          video.oncanplay = () => {
            console.log('üìπ Video can play');
            checkVideo();
          };
          video.onerror = (e) => rejectVideo(new Error(`Video error: ${e}`));
          
          // Start checking immediately
          checkVideo();
        });
        
        if (onProgress) onProgress(15);
        
        // Step 2: Create and load audio
        console.log('üéµ Step 2: Loading audio...');
        const audioUrl = URL.createObjectURL(audioFile);
        const audio = document.createElement('audio');
        audio.src = audioUrl;
        audio.crossOrigin = 'anonymous';
        audio.preload = 'auto';
        audio.volume = 0.8; // Slightly lower to prevent distortion
        
        await new Promise<void>((resolveAudio, rejectAudio) => {
          let attempts = 0;
          const checkAudio = () => {
            attempts++;
            if (audio.readyState >= 3) { // HAVE_FUTURE_DATA
              console.log(`‚úÖ Audio ready after ${attempts} attempts`);
              resolveAudio();
            } else if (attempts > 50) {
              rejectAudio(new Error('Audio loading timeout'));
            } else {
              setTimeout(checkAudio, 100);
            }
          };
          
          audio.onloadeddata = () => {
            console.log('üéµ Audio data loaded');
            checkAudio();
          };
          audio.oncanplay = () => {
            console.log('üéµ Audio can play');
            checkAudio();
          };
          audio.onerror = (e) => rejectAudio(new Error(`Audio error: ${e}`));
          
          checkAudio();
        });
        
        if (onProgress) onProgress(25);
        
        console.log('üìê Step 3: Setting up canvas...');
        this.canvas.width = video.videoWidth || 1920;
        this.canvas.height = video.videoHeight || 1080;
        
        console.log('üé¨ Step 4: Creating media streams...');
        
        // Create video stream from canvas
        const fps = 30;
        const videoStream = this.canvas.captureStream(fps);
        console.log('üìπ Video stream created with FPS:', fps);
        
        // Create audio context for better audio handling
        const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
        
        // Resume audio context if suspended (required by some browsers)
        if (audioContext.state === 'suspended') {
          await audioContext.resume();
        }
        console.log('üéõÔ∏è Audio context state:', audioContext.state);
        
        // Create audio source from the audio element
        const audioSourceNode = audioContext.createMediaElementSource(audio);
        const audioDestinationNode = audioContext.createMediaStreamDestination();
        
        // Connect audio: source -> destination (no effects, direct connection)
        audioSourceNode.connect(audioDestinationNode);
        console.log('üîó Audio connected: source -> destination');
        
        if (onProgress) onProgress(40);
        
        console.log('üåä Step 5: Combining streams...');
        // Create combined stream
        const combinedStream = new MediaStream();
        
        // Add video track
        const videoTracks = videoStream.getVideoTracks();
        videoTracks.forEach(track => {
          combinedStream.addTrack(track);
          console.log('‚úÖ Video track added:', track.kind, track.id);
        });
        
        // Add audio track
        const audioTracks = audioDestinationNode.stream.getAudioTracks();
        audioTracks.forEach(track => {
          combinedStream.addTrack(track);
          console.log('‚úÖ Audio track added:', track.kind, track.id);
        });
        
        console.log('üéØ Combined stream summary:', {
          totalTracks: combinedStream.getTracks().length,
          videoTracks: combinedStream.getVideoTracks().length,
          audioTracks: combinedStream.getAudioTracks().length,
          active: combinedStream.active
        });
        
        if (combinedStream.getAudioTracks().length === 0) {
          throw new Error('CRITICAL: No audio tracks in combined stream!');
        }
        
        if (onProgress) onProgress(55);
        
        console.log('üé¨ Step 6: Setting up MediaRecorder...');
        
        // Try different codec options in order of preference
        const codecOptions = [
          'video/webm;codecs=vp8,opus',
          'video/webm;codecs=vp9,opus', 
          'video/webm;codecs=h264,opus',
          'video/webm;codecs=vp8',
          'video/webm',
          'video/mp4'
        ];
        
        let selectedCodec = '';
        for (const codec of codecOptions) {
          if (MediaRecorder.isTypeSupported(codec)) {
            selectedCodec = codec;
            console.log('‚úÖ Selected codec:', codec);
            break;
          }
        }
        
        if (!selectedCodec) {
          throw new Error('No supported video codec found!');
        }
        
        const mediaRecorder = new MediaRecorder(combinedStream, {
          mimeType: selectedCodec,
          videoBitsPerSecond: 2000000, // 2 Mbps
          audioBitsPerSecond: 128000   // 128 kbps
        });
        
        console.log('üé¨ MediaRecorder created:', {
          mimeType: mediaRecorder.mimeType,
          state: mediaRecorder.state
        });
        
        const recordedChunks: Blob[] = [];
        
        // Set up recording handlers
        mediaRecorder.ondataavailable = (event) => {
          if (event.data && event.data.size > 0) {
            recordedChunks.push(event.data);
            console.log(`üì¶ Chunk ${recordedChunks.length}: ${event.data.size} bytes`);
          }
        };
        
        mediaRecorder.onstop = () => {
          console.log('üèÅ Recording stopped');
          if (recordedChunks.length === 0) {
            reject(new Error('No data was recorded'));
            return;
          }
          
          const finalBlob = new Blob(recordedChunks, { type: selectedCodec });
          console.log('üéâ RECORDING COMPLETE!', {
            chunks: recordedChunks.length,
            size: finalBlob.size,
            sizeMB: (finalBlob.size / 1024 / 1024).toFixed(2)
          });
          
          // Cleanup
          URL.revokeObjectURL(videoUrl);
          URL.revokeObjectURL(audioUrl);
          audioContext.close();
          combinedStream.getTracks().forEach(track => track.stop());
          
          resolve(finalBlob);
        };
        
        mediaRecorder.onerror = (event) => {
          console.error('‚ùå MediaRecorder error:', event);
          reject(new Error('MediaRecorder failed'));
        };
        
        if (onProgress) onProgress(70);
        
        console.log('‚ñ∂Ô∏è Step 7: Starting synchronized playback...');
        
        // Reset media to start
        video.currentTime = 0;
        audio.currentTime = 0;
        
        // Start recording FIRST
        mediaRecorder.start(200); // 200ms chunks for reliability
        console.log('üî¥ Recording started');
        
        // Small delay to ensure recording is active
        await new Promise(resolve => setTimeout(resolve, 100));
        
        // Then start playback
        const videoPlayPromise = video.play();
        const audioPlayPromise = audio.play();
        
        await Promise.all([videoPlayPromise, audioPlayPromise]);
        console.log('‚ñ∂Ô∏è Playback started - Video and Audio playing');
        
        if (onProgress) onProgress(85);
        
        console.log('üéûÔ∏è Step 8: Drawing frames...');
        // Frame drawing loop
        let frameCount = 0;
        const startTime = performance.now();
        
        const drawFrame = () => {
          if (!video.ended && !video.paused && mediaRecorder.state === 'recording') {
            // Draw the current video frame to canvas
            this.ctx.drawImage(video, 0, 0, this.canvas.width, this.canvas.height);
            frameCount++;
            
            // Update progress
            if (video.duration > 0) {
              const videoProgress = (video.currentTime / video.duration) * 10;
              if (onProgress) onProgress(85 + videoProgress);
            }
            
            requestAnimationFrame(drawFrame);
          }
        };
        
        // Start drawing
        requestAnimationFrame(drawFrame);
        
        console.log('‚è≥ Step 9: Waiting for completion...');
        // Wait for video to end
        await new Promise<void>((resolvePlayback) => {
          video.onended = () => {
            const duration = performance.now() - startTime;
            console.log(`üé¨ Video playback ended:`, {
              frames: frameCount,
              duration: `${duration.toFixed(0)}ms`,
              fps: (frameCount / (duration / 1000)).toFixed(1)
            });
            
            // Stop recording after a small delay
            setTimeout(() => {
              if (mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
              }
              audio.pause();
              resolvePlayback();
            }, 500); // Extra buffer time
          };
          
          // Fallback timeout
          setTimeout(() => {
            console.log('‚è∞ Fallback timeout triggered');
            if (mediaRecorder.state === 'recording') {
              mediaRecorder.stop();
            }
            audio.pause();
            resolvePlayback();
          }, (video.duration + 2) * 1000); // Video duration + 2 seconds buffer
        });
        
        if (onProgress) onProgress(100);
        console.log('‚úÖ Guaranteed audio merge process completed');
        
      } catch (error) {
        console.error('‚ùå Error in guaranteed method:', error);
        reject(error);
      }
    });
  }

  private async emergencyFallback(
    videoBlob: Blob,
    audioFile: File,
    onProgress?: (progress: number) => void
  ): Promise<Blob> {
    console.log('üö® EMERGENCY FALLBACK: Returning video with audio note');
    
    // If all else fails, return the original video
    // In a real app, you might want to show a message to the user
    // that audio couldn't be merged but video processing succeeded
    
    if (onProgress) onProgress(100);
    
    console.warn('‚ö†Ô∏è Audio merging failed completely. Returning original video.');
    console.log('üí° Suggestion: Try a different audio file format (MP3, WAV)');
    
    return videoBlob;
  }

  // Cleanup method
  cleanup() {
    if (this.canvas && this.canvas.parentNode) {
      this.canvas.parentNode.removeChild(this.canvas);
    }
  }
}
